import requests
from bs4 import BeautifulSoup
import re
import base64
import hashlib
from urllib.parse import urljoin
import logging

logger = logging.getLogger(__name__)

class ContentScanner:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (compatible; SecurityScanner/1.0)'
        }
        self.known_malicious_patterns = {
            'javascript': [
                r'eval\s*\(',
                r'document\.write\s*\(',
                r'fromCharCode',
                r'btoa\s*\(',
                r'atob\s*\(',
                r'unescape\s*\(',
                r'decodeURIComponent\s*\(',
                r'\\x[0-9a-fA-F]{2}',
                r'\\u[0-9a-fA-F]{4}',
            ],
            'html': [
                r'<iframe.*?src=',
                r'javascript:',
                r'vbscript:',
                r'data:',
                r'<script.*?src=.*?http:',
                r'<object.*?data=',
                r'<embed.*?src=',
            ],
            'css': [
                r'expression\s*\(',
                r'url\s*\(\s*javascript:',
                r'behavior\s*:',
            ]
        }

    def scan_content(self, url):
        """Scan website content for malicious patterns and vulnerabilities"""
        try:
            results = {
                'visual_elements': [],
                'code_structure': {
                    'html': [],
                    'javascript': [],
                    'css': [],
                    'third_party': []
                },
                'malicious_content': [],
                'resource_issues': [],
                'accessibility_issues': [],
                'seo_issues': []
            }

            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')

            # Scan visual elements
            self.scan_visual_elements(soup, results)
            
            # Scan code structure
            self.scan_code_structure(soup, url, results)
            
            # Scan for malicious content
            self.scan_malicious_patterns(soup, response.text, results)
            
            # Scan resources
            self.scan_resources(soup, url, results)
            
            # Check accessibility
            self.check_accessibility(soup, results)
            
            # Check SEO elements
            self.check_seo(soup, results)

            return results

        except Exception as e:
            logger.error(f"Content scan failed: {str(e)}")
            return {'error': str(e)}

    def scan_visual_elements(self, soup, results):
        """Analyze visual elements for security issues"""
        # Check images
        for img in soup.find_all('img'):
            src = img.get('src', '')
            if src:
                if not img.get('alt'):
                    results['accessibility_issues'].append({
                        'type': 'Missing Alt Text',
                        'element': 'img',
                        'source': src,
                        'severity': 'Medium'
                    })
                if src.startswith('data:'):
                    results['visual_elements'].append({
                        'type': 'Base64 Image',
                        'source': src[:50] + '...',
                        'risk_level': 'Medium',
                        'recommendation': 'Avoid using base64 encoded images for better security and performance'
                    })

        # Check forms
        for form in soup.find_all('form'):
            if not form.get('action'):
                results['visual_elements'].append({
                    'type': 'Insecure Form',
                    'issue': 'Missing action attribute',
                    'risk_level': 'High',
                    'recommendation': 'Always specify form action attribute'
                })
            if form.get('method', '').lower() != 'post':
                results['visual_elements'].append({
                    'type': 'Insecure Form',
                    'issue': 'Using GET method',
                    'risk_level': 'Medium',
                    'recommendation': 'Use POST method for forms'
                })

        # Check iframe usage
        for iframe in soup.find_all('iframe'):
            results['visual_elements'].append({
                'type': 'Iframe',
                'source': iframe.get('src', 'unknown'),
                'risk_level': 'Medium',
                'recommendation': 'Use sandbox attribute and proper CSP for iframes'
            })

    def scan_code_structure(self, soup, base_url, results):
        """Analyze code structure for vulnerabilities"""
        # Check inline scripts
        for script in soup.find_all('script'):
            if script.string:
                self.check_javascript_content(script.string, results)
            if src := script.get('src'):
                if src.startswith('http:'):
                    results['code_structure']['javascript'].append({
                        'type': 'Insecure Script Source',
                        'source': src,
                        'risk_level': 'High',
                        'recommendation': 'Use HTTPS for external scripts'
                    })
                if any(vendor in src.lower() for vendor in ['jquery', 'bootstrap', 'angular']):
                    results['code_structure']['third_party'].append({
                        'type': 'Third-party Script',
                        'source': src,
                        'risk_level': 'Info',
                        'recommendation': 'Monitor third-party scripts for vulnerabilities'
                    })

        # Check inline styles
        for style in soup.find_all('style'):
            if style.string:
                self.check_css_content(style.string, results)

        # Check external stylesheets
        for link in soup.find_all('link', rel='stylesheet'):
            if href := link.get('href'):
                if href.startswith('http:'):
                    results['code_structure']['css'].append({
                        'type': 'Insecure Stylesheet',
                        'source': href,
                        'risk_level': 'Medium',
                        'recommendation': 'Use HTTPS for external stylesheets'
                    })

    def scan_malicious_patterns(self, soup, content, results):
        """Scan for malicious patterns in content"""
        # Check for obfuscated JavaScript
        scripts = soup.find_all('script')
        for script in scripts:
            if script.string:
                for pattern_name, pattern in self.known_malicious_patterns['javascript']:
                    if re.search(pattern, script.string):
                        results['malicious_content'].append({
                            'type': 'Suspicious JavaScript',
                            'pattern': pattern_name,
                            'risk_level': 'High',
                            'recommendation': 'Review and remove potentially malicious JavaScript'
                        })

        # Check for malicious HTML patterns
        for pattern in self.known_malicious_patterns['html']:
            if re.search(pattern, content):
                results['malicious_content'].append({
                    'type': 'Suspicious HTML',
                    'pattern': pattern,
                    'risk_level': 'High',
                    'recommendation': 'Review and remove potentially malicious HTML elements'
                })

        # Check for malicious CSS
        styles = soup.find_all('style')
        for style in styles:
            if style.string:
                for pattern in self.known_malicious_patterns['css']:
                    if re.search(pattern, style.string):
                        results['malicious_content'].append({
                            'type': 'Suspicious CSS',
                            'pattern': pattern,
                            'risk_level': 'Medium',
                            'recommendation': 'Review and remove potentially malicious CSS'
                        })

    def scan_resources(self, soup, base_url, results):
        """Scan external resources for security issues"""
        # Check external resources
        resources = {
            'script': soup.find_all('script', src=True),
            'link': soup.find_all('link', href=True),
            'img': soup.find_all('img', src=True),
            'iframe': soup.find_all('iframe', src=True)
        }

        for resource_type, elements in resources.items():
            for element in elements:
                src = element.get('src') or element.get('href')
                if src:
                    full_url = urljoin(base_url, src)
                    if full_url.startswith('http:'):
                        results['resource_issues'].append({
                            'type': f'Insecure {resource_type}',
                            'url': full_url,
                            'risk_level': 'High',
                            'recommendation': f'Use HTTPS for {resource_type} resources'
                        })

    def check_accessibility(self, soup, results):
        """Check for accessibility issues"""
        # Check for ARIA attributes
        interactive_elements = soup.find_all(['button', 'a', 'input', 'select'])
        for element in interactive_elements:
            if not element.get('aria-label') and not element.get('aria-labelledby'):
                results['accessibility_issues'].append({
                    'type': 'Missing ARIA Label',
                    'element': element.name,
                    'severity': 'Medium',
                    'recommendation': 'Add ARIA labels for better accessibility'
                })

    def check_seo(self, soup, results):
        """Check for SEO-related issues"""
        # Check meta tags
        if not soup.find('meta', {'name': 'description'}):
            results['seo_issues'].append({
                'type': 'Missing Meta Description',
                'severity': 'Medium',
                'recommendation': 'Add meta description for better SEO'
            })

        # Check title
        if not soup.find('title'):
            results['seo_issues'].append({
                'type': 'Missing Title',
                'severity': 'High',
                'recommendation': 'Add page title for better SEO'
            })

    def check_javascript_content(self, content, results):
        """Analyze JavaScript content for security issues"""
        suspicious_patterns = {
            'eval': r'eval\s*\(',
            'document.write': r'document\.write\s*\(',
            'innerHTML': r'\.innerHTML\s*=',
            'ajax': r'\.ajax\s*\(',
            'localStorage': r'localStorage\.',
            'sessionStorage': r'sessionStorage\.',
            'cookie': r'document\.cookie'
        }

        for pattern_name, pattern in suspicious_patterns.items():
            if re.search(pattern, content):
                results['code_structure']['javascript'].append({
                    'type': 'Suspicious JavaScript',
                    'pattern': pattern_name,
                    'risk_level': 'Medium',
                    'recommendation': f'Review usage of {pattern_name} for security implications'
                })

    def check_css_content(self, content, results):
        """Analyze CSS content for security issues"""
        suspicious_patterns = {
            'expression': r'expression\s*\(',
            'import': r'@import\s+url\(',
            'behavior': r'behavior\s*:',
            'position:fixed': r'position\s*:\s*fixed'
        }

        for pattern_name, pattern in suspicious_patterns.items():
            if re.search(pattern, content):
                results['code_structure']['css'].append({
                    'type': 'Suspicious CSS',
                    'pattern': pattern_name,
                    'risk_level': 'Low',
                    'recommendation': f'Review usage of {pattern_name} in CSS'
                })